{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def tif_to_vector_by_blocks(\n",
    "    tif_path, out_folder, out_file=\"vector.gpkg\", layer_name=None\n",
    "):\n",
    "    if not os.path.exists(tif_path):\n",
    "        raise FileNotFoundError(f\"Raster file not found: {tif_path}\")\n",
    "\n",
    "    with rasterio.open(tif_path) as src:\n",
    "        meta = src.meta.copy()\n",
    "        crs = src.crs\n",
    "        transform = src.transform\n",
    "        nodata = src.nodata\n",
    "\n",
    "        shapes_list = []\n",
    "\n",
    "        # Recorremos por bloques\n",
    "        for ji, window in tqdm(src.block_windows(1), desc=\"Procesando bloques\"):\n",
    "            data = src.read(1, window=window)\n",
    "            mask = data > 0\n",
    "\n",
    "            if np.any(mask):\n",
    "                window_transform = src.window_transform(window)\n",
    "                for g, val in shapes(data, mask=mask, transform=window_transform):\n",
    "                    shapes_list.append(\n",
    "                        {\"geometry\": shape(g), \"properties\": {\"value\": int(val)}}\n",
    "                    )\n",
    "\n",
    "    print(f\"Total shapes found: {len(shapes_list)}\")\n",
    "    gdf = gpd.GeoDataFrame.from_features(shapes_list, crs=crs)\n",
    "\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "    out_path = os.path.join(out_folder, out_file)\n",
    "    ext = os.path.splitext(out_file)[1].lower()\n",
    "\n",
    "    print(f\"Saving to {out_path} with extension {ext}\")\n",
    "    if ext == \".gpkg\":\n",
    "        if layer_name is None:\n",
    "            layer_name = os.path.splitext(out_file)[0]\n",
    "        gdf.to_file(out_path, driver=\"GPKG\", layer=layer_name)\n",
    "    elif ext == \".shp\":\n",
    "        gdf.to_file(out_path, driver=\"ESRI Shapefile\")\n",
    "    elif ext in [\".geojson\", \".json\"]:\n",
    "        gdf.to_file(out_path, driver=\"GeoJSON\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported output format: {ext}\")\n",
    "\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_to_vector_by_blocks(\n",
    "    \"../results/adef_intg_forest_masked.tif\",\n",
    "    \"../results/\",\n",
    "    out_file=\"adef_intg_forest_masked_by_blocks.gpkg\",\n",
    "    layer_name=\"adef_intg_forest_masked_by_blocks\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from osgeo import gdal, ogr, osr\n",
    "\n",
    "\n",
    "def tif_to_vector_gdal(tif, out_folder, out_file=\"vector.gpkg\", layer_name=None):\n",
    "    \"\"\"\n",
    "    Converts a raster file (TIF) to a vector file using the GDAL Python bindings.\n",
    "\n",
    "    Args:\n",
    "        tif (str): Path to the input raster file.\n",
    "        out_folder (str): Output folder for the vector file.\n",
    "        out_file (str, optional): Output filename (e.g., 'vector.gpkg'). Defaults to 'vector.gpkg'.\n",
    "        layer_name (str, optional): Name of the output layer. Defaults to file name without extension.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the input TIF does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(tif):\n",
    "        raise FileNotFoundError(f\"Input file not found: {tif}\")\n",
    "\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    out_vector = os.path.join(out_folder, out_file)\n",
    "    driver_name = _get_gdal_driver(out_file)\n",
    "    if layer_name is None:\n",
    "        layer_name = os.path.splitext(os.path.basename(out_file))[0]\n",
    "\n",
    "    print(f\"Opening raster: {tif}\")\n",
    "    src_ds = gdal.Open(tif)\n",
    "    band = src_ds.GetRasterBand(1)\n",
    "\n",
    "    # Create output data source\n",
    "    drv = ogr.GetDriverByName(driver_name)\n",
    "    if os.path.exists(out_vector):\n",
    "        drv.DeleteDataSource(out_vector)\n",
    "\n",
    "    dst_ds = drv.CreateDataSource(out_vector)\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromWkt(src_ds.GetProjection())\n",
    "\n",
    "    out_layer = dst_ds.CreateLayer(layer_name, srs=srs, geom_type=ogr.wkbPolygon)\n",
    "    field_defn = ogr.FieldDefn(\"value\", ogr.OFTInteger)\n",
    "    out_layer.CreateField(field_defn)\n",
    "\n",
    "    print(\"Running GDAL Polygonize...\")\n",
    "    gdal.Polygonize(band, None, out_layer, 0, [], callback=None)\n",
    "\n",
    "    # Cleanup\n",
    "    dst_ds.Destroy()\n",
    "    src_ds = None\n",
    "\n",
    "    print(f\"Done. Vector saved to: {out_vector}\")\n",
    "\n",
    "\n",
    "def _get_gdal_driver(filename):\n",
    "    ext = filename.lower().split(\".\")[-1]\n",
    "    if ext == \"gpkg\":\n",
    "        return \"GPKG\"\n",
    "    elif ext in [\"shp\"]:\n",
    "        return \"ESRI Shapefile\"\n",
    "    elif ext in [\"json\", \"geojson\"]:\n",
    "        return \"GeoJSON\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_to_vector_gdal(\n",
    "    \"../results/adef_intg_forest_masked.tif\",\n",
    "    \"../results/\",\n",
    "    out_file=\"adef_intg_forest_masked_by_gdal.gpkg\",\n",
    "    layer_name=\"adef_intg_forest_masked_by_gdal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Crear a gdf a partir de los shapes\n",
    "geoms = gpd.GeoDataFrame.from_records(\n",
    "    ((shape(geom), value) for geom, value in shapes),\n",
    "    columns=[\"geometry\", \"value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "False + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el modulo editable\n",
    "from adef_intg import utils_adef\n",
    "from adef_intg import locking\n",
    "from pathlib import Path\n",
    "import rioxarray as rxr\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_read = locking.get_safe_lock(\"rio-read\")\n",
    "lock_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock_write = locking.get_safe_lock(\"rio-write\")\n",
    "lock_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = utils_adef.get_wfs_layer(\n",
    "    wfs_url=\"https://geoserver.icf.gob.hn/icfpub/wfs\",\n",
    "    layer_name=\"icfpub:limite_departamentos_gp\",\n",
    "    version=\"1.1.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_adef_intg = (\n",
    "    \"https://data-api.globalforestwatch.org/dataset/gfw_integrated_alerts/\"\n",
    "    \"latest/download/geotiff?grid=10/100000&tile_id=20N_090W&pixel_meaning=\"\n",
    "    \"date_conf&x-api-key=2d60cd88-8348-4c0f-a6d5-bd9adb585a8c\"\n",
    ")\n",
    "tif = rxr.open_rasterio(\n",
    "    url_adef_intg,\n",
    "    chunks=True,\n",
    "    # lock=False,\n",
    "    lock=threading.Lock(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_adef.clip_tif_to_ext(tif=tif, vector=vector, out_tif=\"../data/adef_intg_hn.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"../\").resolve()\n",
    "confidence = 1\n",
    "utils_adef.mask_adef_hn_by_forest(\n",
    "    tif_forest18=base_dir / \"data/bosque18_lzw.tif\",\n",
    "    tif_forest24=base_dir / \"data/bosque24_lzw.tif\",\n",
    "    tif_forest14=base_dir / \"data/bosque14_lzw.tif\",\n",
    "    tif_adef_hn=base_dir / \"data/adef_intg_hn.tif\",\n",
    "    tif_forest14_match=base_dir / \"data/bosque14_lzw_match.tif\",\n",
    "    tif_forest18_match=base_dir / \"data/bosque18_lzw_match.tif\",\n",
    "    tif_forest24_match=base_dir / \"data/bosque24_lzw_match.tif\",\n",
    "    tif_out=base_dir / \"results/adef_intg_hn_forest_masked.tif\",\n",
    "    confidence_integ=confidence,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Configuraciones y librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from owslib.wfs import WebFeatureService\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "\n",
    "# Ignorar advertencias de GeoPandas relacionadas con CRS\n",
    "warnings.filterwarnings(\"ignore\", message=\"Geometry is in a geographic CRS.\")\n",
    "\n",
    "# Opcional: Ignorar advertencias de Shapely si aparecen\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning)\n",
    "\n",
    "# Agregar la ruta del directorio padre al sys.path\n",
    "try:\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "    base_dir = Path(__file__).resolve().parent.parent\n",
    "except:\n",
    "    __file__ = os.path.abspath(\"adef_intg.ipynb\")\n",
    "    sys.path.append(os.path.dirname(os.path.dirname(__file__)))\n",
    "    base_dir = Path(__file__).resolve().parent.parent\n",
    "\n",
    "from src import utils_adef\n",
    "\n",
    "\n",
    "def run_adef_process(\n",
    "    confidence, out_folder, out_file, layer_name, start_date, end_date, base_dir\n",
    "):\n",
    "    start_time = time.time()\n",
    "    print(\n",
    "        f\"🚀 Iniciando el procesamiento de alertas integradas a las: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(start_time))} 🌍\"\n",
    "    )\n",
    "    # Definir la URL de las alertas\n",
    "    url_adef_intg = (\n",
    "        \"https://data-api.globalforestwatch.org/dataset/gfw_integrated_alerts/\"\n",
    "        \"latest/download/geotiff?grid=10/100000&tile_id=20N_090W&pixel_meaning=\"\n",
    "        \"date_conf&x-api-key=2d60cd88-8348-4c0f-a6d5-bd9adb585a8c\"\n",
    "    )\n",
    "\n",
    "    # Descargar los tif de bosque\n",
    "    TIFS = {\n",
    "        \"bosque14_lzw\": \"https://git.icf.gob.hn/alopez/adef-integ-tools/-/raw/main/data/bosque14_lzw.tif\",\n",
    "        \"bosque18_lzw\": \"https://git.icf.gob.hn/alopez/adef-integ-tools/-/raw/main/data/bosque18_lzw.tif\",\n",
    "        \"bosque24_lzw\": \"https://git.icf.gob.hn/alopez/adef-integ-tools/-/raw/main/data/bosque24_lzw.tif\",\n",
    "    }\n",
    "    for tif_name, tif_url in TIFS.items():\n",
    "        tif_path = base_dir / \"data\" / f\"{tif_name}.tif\"\n",
    "        if not tif_path.exists():\n",
    "            print(f\"Descargando {tif_name}...\")\n",
    "            utils_adef.dw_tif(\n",
    "                url=tif_url,\n",
    "                tif_out=tif_path,\n",
    "            )\n",
    "            print(f\"{tif_name} descargado y guardado en {tif_path}\")\n",
    "        else:\n",
    "            print(f\"{tif_name} ya existe en {tif_path}, se omitirá la descarga.\")\n",
    "\n",
    "    # Preparar la data para análisis\n",
    "    ## Preparar los datos auxiliares\n",
    "    # Crear la conexion al servicio WFS\n",
    "    url_icf_wfs = \"https://geoserver.icf.gob.hn/icfpub/wfs\"\n",
    "    wfs_icf = WebFeatureService(url_icf_wfs, version=\"1.1.0\")\n",
    "\n",
    "    # Obtener el GeoDataFrame de los departamentos de Honduras\n",
    "    lyr_dep = \"icfpub:limite_departamentos_gp\"\n",
    "    dep_response = wfs_icf.getfeature(typename=lyr_dep, outputFormat=\"application/json\")\n",
    "    gdf_dep = gpd.read_file(dep_response)\n",
    "\n",
    "    # Preparar el tif por el área y fechas de interés\n",
    "    print(\"...Iniciando el enmascaramientos de las alertas integradas\")\n",
    "    # Leer el tif de alertas\n",
    "    tif_adef_intg = rxr.open_rasterio(url_adef_intg, lock=True, chunks=True)\n",
    "\n",
    "    # Cortar por el extend de Honduras\n",
    "    if gdf_dep.crs != tif_adef_intg.rio.crs:\n",
    "        gdf_dep_reproyectado = gdf_dep.to_crs(tif_adef_intg.rio.crs)\n",
    "        tif_adef_intg_hn = tif_adef_intg.rio.clip_box(\n",
    "            *gdf_dep_reproyectado.total_bounds\n",
    "        )\n",
    "        tif_adef_intg_hn.name = \"adef_intg_hn\"\n",
    "        print(\n",
    "            \"Se realizó clip al raster con el GeoDataFrame de departamentos reproyectado\"\n",
    "        )\n",
    "    else:\n",
    "        tif_adef_intg_hn = tif_adef_intg.rio.clip_box(*gdf_dep.total_bounds)\n",
    "        tif_adef_intg_hn.name = \"adef_intg_hn\"\n",
    "\n",
    "    if start_date and end_date:\n",
    "        tif_adef_intg_hn, _, _ = utils_adef.filter_adef_intg_time(\n",
    "            tif_adef_intg_hn,\n",
    "            (\"Range\", start_date, end_date),\n",
    "            base_dir / \"data/adef_intg_hn.tif\",\n",
    "        )\n",
    "        print(f\"Se realizó el filtrado por fechas {start_date} - {end_date}\")\n",
    "    else:\n",
    "        tif_adef_intg_hn.rio.to_raster(\n",
    "            base_dir / \"data/adef_intg_hn.tif\",\n",
    "            tiled=True,\n",
    "            lock=threading.Lock(),\n",
    "            compress=\"DEFLATE\",\n",
    "        )\n",
    "        print(\"Se procesó el raster sin filtrar por fechas\")\n",
    "\n",
    "    utils_adef.mask_adef_hn_by_forest(\n",
    "        tif_forest18=base_dir / \"data/bosque18_lzw.tif\",\n",
    "        tif_forest24=base_dir / \"data/bosque24_lzw.tif\",\n",
    "        tif_forest14=base_dir / \"data/bosque14_lzw.tif\",\n",
    "        tif_adef_hn=base_dir / \"data/adef_intg_hn.tif\",\n",
    "        tif_forest14_match=base_dir / \"data/bosque14_lzw_match.tif\",\n",
    "        tif_forest18_match=base_dir / \"data/bosque18_lzw_match.tif\",\n",
    "        tif_forest24_match=base_dir / \"data/bosque24_lzw_match.tif\",\n",
    "        tif_out=base_dir / \"results/adef_intg_hn_forest_masked.tif\",\n",
    "        confidence_integ=confidence,\n",
    "    )\n",
    "    print(\"Se realizó el enmascaramiento de las alertas integradas por el bosque\")\n",
    "\n",
    "    # Crear el vector de alertas\n",
    "    print(\"...creando el vector de las alertas integradas\")\n",
    "\n",
    "    # Crear gpkg de las alertas\n",
    "    utils_adef.tif_to_vector(\n",
    "        tif=base_dir / \"results/adef_intg_hn_forest_masked.tif\",\n",
    "        out_folder=out_folder,\n",
    "        out_file=out_file,\n",
    "        layer_name=layer_name,\n",
    "    )\n",
    "    # Agregar la fecha de la alerta y actualizar los datos de la capa\n",
    "    gdf = gpd.read_file(os.path.join(out_folder, out_file), layer=layer_name)\n",
    "    gdf = utils_adef.calculate_decompose_date(gdf, \"value\", \"INTEGRATED\")\n",
    "    gdf[\"confidence\"] = gdf[\"value\"] // 10000\n",
    "    gdf.to_file(\n",
    "        out_folder / out_file,\n",
    "        layer=layer_name,\n",
    "        driver=\"GPKG\",\n",
    "        index=False,\n",
    "    )\n",
    "    time_end = time.time()\n",
    "    print(\n",
    "        f\"Finalizando el procesamiento de alertas integradas a las: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time_end))}\"\n",
    "    )\n",
    "    elapsed_time = time_end - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(\n",
    "        f\"El tiempo de procesamiento fue de: {int(hours)} horas, {int(minutes)} minutos y {seconds:.2f} segundos\"\n",
    "    )\n",
    "    return gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
